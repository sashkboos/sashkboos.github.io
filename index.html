<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Saleh Ashkboos' Personal Page</title>
</head>
<body>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="images/Saleh_suit.jpg" alt="Wu" width="150px" />&nbsp;</td>
<td align="left"><h1>Saleh Ashkboos<br /></h1>
<p>Research Assistant at <a href="https://spcl.inf.ethz.ch/">Scalable Parallel Computing Lab</a></br>
	Computer Science Department,</br>
	ETH ZÃ¼rich.<br />
<br />
<i>saleh.ashkboos [at] inf [dot] ethz [dot] ch</i><br />

<a href="http://scholar.google.com/citations?user=N3RteqgAAAAJ&hl=en">Google Scholar</a> &nbsp;
<a href="https://dblp.uni-trier.de/pers/a/Ashkboos:Saleh.html">DBLP</a> &nbsp;
<a href="https://www.linkedin.com/in/saleh-ashkboos-806628161/">LinkedIn</a></p>
</td></tr></table>

<h2>About</h2>
<p>
I'm a fourth-year Ph.D. student in the Computer Science Department of ETH Zurich. I am fortunate to be advised by Professor <a href="  https://htor.inf.ethz.ch/">Torsten Hoefler</a> and
	Professor <a href="  https://people.csail.mit.edu/alistarh/">Dan Alistarh</a>. <br />My research focuses on accelerating deep neural network training. Also, I'm working on developing systems and algorithms for large scale graph processing. I am also an associated doctoral student of the <a href="https://ai.ethz.ch">ETH AI Center</a>.


<br /><br />

Before joining ETH, I received my Master's degree in Computer Science from the <a href="http://www.en.sharif.edu/">Sharif University of Technology</a> advised by Professor <a href="http://math.sharif.ir/faculties/daneshgar">Amir Daneshgar</A> in 2019.


</p>

  
<h2>News</h2>
<ul>
<li><p> 2024/09: "<a href="https://arxiv.org/pdf/2404.00456">QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs  </a>" accepted at  <a href="https://neurips.cc">NeurIPS24</A>. (<a href="https://github.com/spcl/QuaRot">Github</A>)</p></li>
<li><p> 2024/09: "<a href="https://arxiv.org/pdf/2310.09259">QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language Models
  </a>" accepted at  <a href="https://2024.emnlp.org">EMNLP24</A>. (<a href="https://github.com/IST-DASLab/QUIK">Github</A>)</p></li>
<li><p> 2024/04: I will join <a href="https://www.apple.com">Apple</a> as a Research Intern.</p></li>
<li><p> 2024/02: I gave an invited talk on "<em>The Art of LLM Compression</em>" at <a href="https://www.amazon.com">Amazon</a>.</p></li>
<li><p> 2024/01: "<a href="https://arxiv.org/pdf/2401.15024">SliceGPT</a>" and "<a href="https://arxiv.org/abs/2306.03078">SpQR</a>" are accepted at  <a href="https://iclr.cc">ICLR24</A>.</p></li> 
<li><p> 2023/04: I will join <a href="https://www.microsoft.com/">Microsoft</a> for a summer internship.</p></li>
<li><p> 2023/01: "<a href="https://arxiv.org/abs/2210.17323">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a>" accepted at  <a href="https://iclr.cc">ICLR23</A>.</p></li>	
<li><p> 2022/11: "<a href="https://arxiv.org/pdf/2208.11469v1.pdf">ProbGraph: High-Performance and High-Accuracy Graph Mining with Probabilistic Set Representations  </a>" selected as the best paper at <a href="https://sc22.supercomputing.org">SC22</A>.</p></li>
<li><p> 2022/09: "<a href="https://arxiv.org/abs/2206.14786">ENS-10: A Dataset For Post-Processing Ensemble Weather Forecasts </a>"  accepted at <a href="https://neurips.cc">Neurips22</A>. (<a href="https://github.com/spcl/ens10">Github</A>)</p></li>
<!-- <li><p> 2022/08: "<a href="https://arxiv.org/pdf/2208.11469v1.pdf">ProbGraph: High-Performance and High-Accuracy Graph Mining with Probabilistic Set Representations  </a>" selected as the best paper finalist at <a href="https://sc22.supercomputing.org">SC22</A>.</p></li> -->
<!-- <li><p> 2022/08: "<a href="https://arxiv.org/pdf/2208.11469v1.pdf">ProbGraph: High-Performance and High-Accuracy Graph Mining with Probabilistic Set Representations  </a>" accepted at  <a href="https://sc22.supercomputing.org">SC22</A>.</p></li> -->
<!-- <li><p> 2022/07: I will join <a href="http://axelera.ai">AxeleraAI</a> for a summer internship.</p></li> -->
<!-- <li><p> 2022/05: "<a href="https://arxiv.org/pdf/2106.00761.pdf">Motif Prediction with Graph Neural Networks  </a>" accepted at  <a href="https://kdd.org/kdd2022/">KDD'22</A>.</p></li>
<li><p> 2021/05: "<a href="https://arxiv.org/abs/2106.15565">Flare: Flexible In-Network Allreduce  </a>" accepted at  <a href="https://sc21.supercomputing.org">SC21</A>.</p></li>
<li><p>2021/04: I Joined SPCL Lab.</p></li>
<li><p> 2021/01: "<a href="https://openreview.net/forum?id=t86MwoUCCNe">New Bounds For Distributed Mean Estimation and Variance Reduction</a>" accepted at  <a href="https://openreview.net/group?id=ICLR.cc/2021/Conference">ICLR 2021</A>.</p></li>

<li><p> 2020/08: "<a href="https://www.sciencedirect.com/science/article/pii/S0166218X20304984">Multi-way sparsest cut problem on trees with a control on the number of parts and outliers</a>" accepted at  <a href="https://www.sciencedirect.com/journal/discrete-applied-mathematics">Discrete Applied Mathematics</A>.</p></li>
<li><p>2020/01: I successfully defended my Master dissertation.</p></li>
<li><p> 2019/10: "<a href="https://dl.acm.org/doi/pdf/10.1145/3295500.3356222">Sparcml: High-performance sparse communication for machine learning</a>" accepted at  <a href="https://sc19.supercomputing.org/">SC19</A>.</p></li> -->

</ul>

<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5cu21nn8a5l&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33&amp;bv=60" async="async"></script>

<!--   
<h2>Publications</h2>
<h3>Book Chapter </h3>
 <ul>
   <li>
      <p>Object Detection with Convolutional Neural Networks
        <a href="https://arxiv.org/pdf/1912.01844.pdf">[PDF]</a></br>
        Kaidong Li, Wenchi Ma, Usman Sajid, <b>Yuanwei Wu</b> and Guanghui Wang</br>
        Deep Learning in Computer Vision: Principles and Applications, ISBN 9781138544420, 2020.
      </p>
   </li>
 </ul>
  
<h3>Journal Publications</h3>
<ul>
   <li>
      <p>MDFN: Multi-scale deep feature learning network for object detection
        <a href="https://arxiv.org/pdf/1912.04514.pdf">[PDF]</a></br>
        Wenchi Ma, <b>Yuanwei Wu</b>, Feng Cen, Guanghui Wang</br>
        Pattern Recognition (PR), 2020.
      </p>
   </li>

  <li>
     <p>Real-time Obstacle Detection and Tracking for Sense-and-Avoid Mechanism in UAVs
        <a href="https://ieeexplore.ieee.org/document/8286944">[PDF]</a></br>
        Sushil Bharati, <b>Yuanwei Wu</b>, Yao Sui, Curtis Padgett and Guanghui Wang</br>
        IEEE Transactions on Intelligent Vehicles, Volume: 3 , Issue: 2, pp:185-197, 2018.
     </p>
   </li>

   <li>
     <p>Vision-based Real-Time Aerial Object Localization and Tracking for UAV Sensing System
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8080161">[PDF]</a>
        <a href="https://github.com/RyanCV/Vision-based-OLT">[Code]</a></br>
        <b>Yuanwei Wu</b>, Yao Sui, and Guanghui Wang</br>
        IEEE Access, Vol. 5, 23969 - 23978, 2017.
     </p>
   </li>
 </ul>
  
<h3>Conference Publications</h3>
<ul>
   <li>
      <p>Self-Orthogonality Module: A Network Architecture Plug-in for Learning Orthogonal Filters
        <a href="http://openaccess.thecvf.com/content_WACV_2020/papers/Zhang_Self-Orthogonality_Module_A_Network_Architecture_Plug-in_for_Learning_Orthogonal_Filters_WACV_2020_paper.pdf">[PDF]</a></br>
        Ziming Zhang, Wenchi Ma, <b>Yuanwei Wu</b> and Guanghui Wang</br>
        The IEEE Winter Conference on Applications of Computer Vision (WACV), 2020.
      </p>
   </li>

   <li>
     <p>Unsupervised Joint 3D Object Model Learning and 6D Pose Estimation for Depth-Based Instance Segmentation
        <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/R6D/Wu_Unsupervised_Joint_3D_Object_Model_Learning_and_6D_Pose_Estimation_ICCVW_2019_paper.pdf">[PDF]</a></br>
        <b>Yuanwei Wu</b>, Tim K. Marks, Anoop Cherian, Siheng Chen, Chen Feng, Guanghui Wang and Alan Sullivan</br>
        The IEEE International Conference on Computer Vision (ICCV) 2019, 5th International Workshop on Recovering 6D Object Pose (R6D).
     </p>
   </li>

    <li>
     <p>Unsupervised Deep Feature Transfer for Low Resolution Image Classification
        <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/RLQ/Wu_Unsupervised_Deep_Feature_Transfer_for_Low_Resolution_Image_Classification_ICCVW_2019_paper.pdf">[PDF]</a></br>
        <b>Yuanwei Wu</b>, Ziming Zhang and Guanghui Wang</br>
        The IEEE International Conference on Computer Vision (ICCV) 2019, Workshop and Challenge on Real-World Recognition from Low-Quality Images and Videos (RLQ).
     </p>
   </li>

<li>
     <p>BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning
        <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_BPGrad_Towards_Global_CVPR_2018_paper.pdf">[PDF]</a>
        <a href="2018_CVPR/2018_CVPR_BPGrad_poster.pdf">[Poster]</a></br>
        Ziming Zhang*, <b>Yuanwei Wu</b>*, and Guanghui Wang (* Equal contribution)</br>
        The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.
     </p>
   </li>

<li>
     <p>MDCN: Multi-Scale, Deep Inception Convolutional Neural Networks for Efficient Object Detection
        <a href="https://arxiv.org/pdf/1809.01791.pdf">[PDF]</a>
        <a href="ICPR2018/ICPR18_poster.pdf">[Poster]</a></br>
        Wenchi Ma, <b>Yuanwei Wu</b>, Zongbo Wang and Guanghui Wang</br>
        International Conference on Pattern Recognition (ICPR), 2018.
     </p>
   </li>

<li>
     <p>Fast and Robust Object Tracking with Adaptive Detection
        <a href="https://ieeexplore.ieee.org/document/7814672">[PDF]</a></br>
        Sushil Bharati, Soumyaroop Nandi, <b>Yuanwei Wu</b>, Yao Sui and Guanghui Wang</br>
        IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI), 2016.
     </p>
   </li>
 </ul>

<h2> Research Experience</h2>
<ul>
		<li>Graduate Research Assistant, The University of Kansas, Lawrence, KS, August 2015 - December 2017</li>
    <li>Research Intern, Mitsubishi Electric Research Laboratories, Cambridge, MA, September 2018 - August 2019</li>
		<li>Research Intern, Comcast Applied AI Labs, Washington, D.C., May 2018 - August 2018</li>
		<li>AI Engineer Intern, Midea Emerging Technology Center, San Jose, CA, May 2017 - August 2017</li>
		<li>Research Intern, Mitsubishi Electric Research Laboratories, Cambridge, MA, January 2017 - March 2017</li>
</ul>

<h2>Teaching Experience</h2>
<ul>
 <li>Graduate Teaching Assistant, The University of Kansas
      <ul> 
        <li> EECS 268: Programming II, C++ (Fall 2017) </li>
      </ul>
 </li>
 <li> Teaching Assistant, Tufts University
      <ul>
        <li> ES3: Introduction to Electrical Engineering (Fall 2012)</li>
        <li> ES4: Introduction to Digital Logic Circuits (Spring 2013)</li>
      </ul>
  </li>
</ul>

<h2>Professional Activities</h2>
<ul>
	<li>Journal Reviewer
		<ul>
		<li>IEEE Transactions on Multimedia (TMM)</li>
		<li>Pattern Recognition (PR)</li>
		<li>IEEE Access</li>
		<li>IEEE Geoscience and Remote Sensing Letters (GRSL)</li>
		<li>IEEE Transactions on Medical Imaging (TMI)</li>
		<li>Applied Sciences</li>
		<li>Sensors</li>
		</ul>
	</li>
	<li>Conference Reviewer
		<ul>
    <li>IEEE Winter Conference on Applications of Computer Vision (WACV), 2019, 2020</li>
		<li>International Conference on Pattern Recognition (ICPR), 2020</li>
		<li>International Joint Conference on Artificial Intelligence (IJCAI), 2019</li>
		<li>IEEE International Conference on Tools with Artificial Intelligence (ICTAI), 2018, 2019</li>
		</ul>
	</li>
	</ul>

<h2>Miscellaneous</h2>
<ul>
	   <li><A href="http://3dvision.princeton.edu/courses/COS598/2014sp/slides/lecture21_how2research.pdf">How to do research in Computer Vision</A></li>
      	   <li><A href="http://www.deeplearningindaba.com/uploads/1/0/2/6/102657286/research-paper-writing.pdf">How to write a great 
research paper</A></li>
	   <li><A href="https://github.com/RyanCV/RyanCV.github.io/blob/master/How%20to%20Review%20for%20CVPR.pptx">How to review CVPR
research paper</A></li>
</ul>

<hr align=left>
    <footer>                
    <div class="page-header" style="margin-top: 0px;"></div>
    <div class="col-md-2" style="text-align: center">
      <a href="http://info.flagcounter.com/wYum"><img src="http://s10.flagcounter.com/count2/wYum/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
      <span>Last updated: May, 2020</span>
    </div>
  </footer>
</div>
</div>
 -->
</body>
</html>


